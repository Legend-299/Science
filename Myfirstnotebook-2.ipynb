{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4dd2cdc-2236-4c7c-a6a4-c16a8c86bb23",
   "metadata": {},
   "source": [
    "# My Data Science Internship from Hell: A Comedy of Errors\n",
    "\n",
    "## Introduction: My Descent into the Data Abyss\n",
    "\n",
    "So, you want to be a data scientist?  You dream of wrangling data, building models, and predicting the future? Well, let me tell you about *my* data science internship... a three-month odyssey of epic proportions, filled with more bugs than a rainforest and more NaN values than the ocean has water. Buckle up, because this is a story of how I learned that sometimes, the best prediction you can make is that you're going to need a stiff drink at the end of the day.\n",
    "\n",
    "It all started with a fateful email, offering me an internship at the *highly* prestigious Data Wizards Inc.  (They're so prestigious, they haven't updated their website since 1998.  It's a real time capsule of dial-up modems and animated GIFs.) You can see their cutting-edge design for yourself [here](https://imgur.com/a/555OZV5). They promised cutting-edge data science, groundbreaking insights, and free pizza. (Spoiler alert: They delivered on none of these promises. Unless you consider lukewarm coffee and stale bagels \"pizza.\")\n",
    "\n",
    "Their office was... unique.  Let's just say it had a certain \"rustic charm.\"  Think \"run-down basement meets hoarder's paradise,\" with a dash of \"suspicious stains\" thrown in for good measure.  But hey, I figured, it's all about the experience, right?  (I was so naive.)  I should have known something was amiss when I saw their website.  It was a digital monument to bad data, a testament to the fact that even data scientists sometimes struggle with… well, data.  It reminded me of this article I read about the [challenges of data cleaning](https://www.kdnuggets.com/essential-data-cleaning-techniques-accurate-machine-learning-models#:~:text=Master%20essential%20data%20cleaning%20techniques,using%20a%20real%2Dworld%20project.). (A must-read for anyone who thinks data science is all glamorous modeling and fancy algorithms.  It's mostly just cleaning up messes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1b585-e2b0-45e9-b0f2-51361e7c74ac",
   "metadata": {},
   "source": [
    "## The Offer: A Glimmer of Hope (or So I Thought)\n",
    "\n",
    "It all started so innocently.  I was a bright-eyed, bushy-tailed data science student, eager to apply my newly acquired skills in the real world.  Then, I got *the call*.  An internship! At *prestigious* \"Data Wizards Inc.\"!  I was ecstatic!  I imagined myself surrounded by brilliant minds, solving complex problems, and maybe even getting free pizza.  Little did I know..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67278303-e28c-49fb-ace2-3a1db789ea21",
   "metadata": {},
   "source": [
    "## Day 1: Welcome to the Jungle (of Bad Data)\n",
    "\n",
    "My first day was... interesting.  I was introduced to my \"mentor,\" a guy named Bob who looked like he hadn't slept in a week.  \"Here's your project,\" he mumbled, handing me a hard drive that looked like it had been through a warzone.  \"It's... uh... 'customer data.'  Good luck.\"  And with that, he vanished.  I plugged in the hard drive and... well, let's just say the data was less \"customer insights\" and more \"customer nightmares.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37f98a58-a078-4b82-a308-a23e0d5bcdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id              name   age                  email   income  \\\n",
      "0            1         Bob Smith  42.0  bob.smith@example.com  60000.0   \n",
      "1            2          Jane Doe  28.0   jane.doe@example.com  80000.0   \n",
      "2            3          John Doe   NaN   john.doe@example.com      NaN   \n",
      "3            4  Alice Wonderland  22.0   alice@wonderland.com  40000.0   \n",
      "4            5          The Dude  55.0  the.dude@lebowski.com  20000.0   \n",
      "\n",
      "                  WTF   \n",
      "0          Likes cats   \n",
      "1  Watches reality TV   \n",
      "2  Loves spreadsheets   \n",
      "3    Collects teacups   \n",
      "4              Abides   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    customer_data = pd.read_csv(\"customer_data_from_hell.csv\")  # The filename was ominous, I should have known\n",
    "except FileNotFoundError:\n",
    "    print(\"The data is missing! Just like my will to live.\")\n",
    "    exit()\n",
    "\n",
    "print(customer_data.head()) # A peek into the abyss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f95990-5744-4ea1-b211-3a744bbfe512",
   "metadata": {},
   "source": [
    "## Data Cleaning: My Descent into Madness\n",
    "\n",
    "The data was a mess.  Missing values everywhere.  Inconsistent formatting.  One column was literally labeled \"WTF.\"  I spent the next two weeks trying to clean it up.  It was like trying to organize a hoarder's attic, except the attic was filled with bad data and the hoarder was a rogue AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe382c9f-fc57-4370-a439-b5ff61c0cce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'WTF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'WTF'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m customer_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWTF\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m customer_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWTF\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m¯\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_(ツ)_/¯\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'WTF'"
     ]
    }
   ],
   "source": [
    "customer_data['WTF'] = customer_data['WTF'].fillna(r\"¯\\_(ツ)_/¯\")  # Use a raw string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24fbfd8-d14d-4437-b2d2-9ec5d0541300",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data['WTF'] = customer_data['WTF'].fillna(\"¯\\\\_(ツ)_/¯\")  # Escape the backslash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3124dc-f7d0-4e85-863e-d5e14398d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    customer_data = pd.read_csv(\"customer_data_from_hell.csv\")\n",
    "    print(\"CSV loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "customer_data.columns = customer_data.columns.str.strip()\n",
    "print(customer_data.columns)\n",
    "\n",
    "print(customer_data.head())\n",
    "\n",
    "customer_data['age'] = customer_data['age'].fillna(customer_data['age'].mean())\n",
    "customer_data['email'] = customer_data['email'].fillna(\"no_email@example.com\")\n",
    "customer_data['WTF'] = customer_data['WTF'].fillna(r\"¯\\_(ツ)_/¯\")  # <--- Corrected: Using raw string\n",
    "\n",
    "# ... rest of your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb487292-88e9-4e45-bae2-dc35d1ee7329",
   "metadata": {},
   "source": [
    "... After weeks of wrestling with the data, I had finally tamed the beast (or at least convinced it to take a nap).  Now it was time to unleash my creativity and… make up some new features!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a58e7f-a3fb-4455-ab00-f7e58aef4b7c",
   "metadata": {},
   "source": [
    "## Feature Engineering:  Because My Data Needed More… Stuff\n",
    "\n",
    "I decided that my data needed more… *features*.  Because more features = more science, right? (Don't quote me on that.) First, I created the \"Customer Prosperity Quotient,\" a highly sophisticated metric that takes into account age, income, and how many times they mention \"Baby Yoda\" in their online reviews.  It's still in beta testing, but I'm pretty sure it's going to revolutionize the world of marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289778a0-062c-4a26-94a3-fd2695c56b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data['customer_prosperity_quotient'] = (customer_data['income'] / (customer_data['age'] + 1)) * customer_data['WTF'].str.count('Baby Yoda') # Example calculation - make it funny!\n",
    "customer_data['age_group'] = pd.cut(customer_data['age'], bins=[0, 25, 45, 65, 120], labels=[\"Fresh-Faced\", \"Slightly Wrinkled\", \"Vintage\", \"Ancient\"], right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d2e5ec-20b8-442c-8f0f-7112d9a44e63",
   "metadata": {},
   "source": [
    "## Model Building: The \"Quantum Customer Analyzer 9000\" (Because Science!)\n",
    "\n",
    "Behold! The Quantum Customer Analyzer 9000! (I added \"Quantum\" because it makes it sound way more advanced.  Don't tell anyone it's just a bunch of random math.)  This revolutionary algorithm uses a complex system of weighted averages, fuzzy logic, and a proprietary blend of unicorn tears and caffeine to predict customer income with unparalleled accuracy. (Okay, maybe \"unparalleled\" is a bit strong.  Let's say \"mildly amusing.\")\n",
    "\n",
    "The model training was a grueling ordeal.  I spent weeks calibrating the flux capacitor, aligning the dilithium crystals, and performing ritualistic chants to appease the Data Gods. (Bob from IT just looked at me weird.) But finally, after much toil and tribulation (and several existential crises), the model was ready.  Or so I hoped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c02c60-4842-4d8f-85a0-c58c72645ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Needed for some silliness\n",
    "\n",
    "# Absurdly complex calculation for Customer Prosperity Quotient\n",
    "customer_data['customer_prosperity_quotient'] = (\n",
    "    np.sqrt(customer_data['income'] * customer_data['age']) +  # Square root for \"scientific\" effect\n",
    "    customer_data['WTF'].str.len() * 42 -  # Multiply by a random number for no reason\n",
    "    np.log1p(customer_data['age'] + 1)  # Logarithm because it sounds smart\n",
    ") / (customer_data['age'] + 1)  # Divide by age because... why not?\n",
    "\n",
    "# Ridiculous income prediction model\n",
    "average_income = customer_data['income'].mean()\n",
    "customer_data['predicted_income'] = (\n",
    "    customer_data['age'].apply(lambda age: average_income * (1 + np.sin(age / 10))) + # Sine wave because it's fancy\n",
    "    np.random.normal(0, 10000, len(customer_data)) # Add some random noise for \"realism\"\n",
    ")\n",
    "\n",
    "# Clip predicted income to reasonable values (just in case it goes completely bonkers)\n",
    "customer_data['predicted_income'] = np.clip(customer_data['predicted_income'], 0, 1000000) # Prevents insane predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917a483-02ec-4e51-a457-a10ad8c67905",
   "metadata": {},
   "source": [
    "## Results:  A Symphony of Statistical Silliness\n",
    "\n",
    "The moment of truth! I unleashed the Quantum Customer Analyzer 9000 on my meticulously crafted dataset.  The results?  Prepare to be… mildly entertained.\n",
    "\n",
    "My model predicted that a 1-year-old would have a higher income than Jeff Bezos.  It also predicted that Gandalf, a wizard from Middle-earth, would be obsessed with buying the latest iPhone.  Clearly, my algorithm is a masterpiece of… well, I'm not entirely sure what it's a masterpiece of.  But it's definitely… something.\n",
    "\n",
    "The Mean Squared Error?  Let's just say it's a number that would make even the most seasoned statistician weep.  It's so big, it could probably be used to measure the distance between the Earth and the Andromeda galaxy.\n",
    "\n",
    "Here's a glimpse of the \"amazing\" predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61e833-6c3d-4ff3-84fd-9215fbafd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customer_data[[\n",
    "    'name', 'age', 'income', 'predicted_income',\n",
    "    'age_group', 'customer_prosperity_quotient'\n",
    "]])\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(customer_data['income'], customer_data['predicted_income'])\n",
    "print(f\"Mean Squared Error: {mse:.2f}.  My model is clearly… unique. (And by unique, I mean hilariously inaccurate.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17ec68-9934-41f7-bc3c-0f23ca2ba830",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data_cleaned = customer_data.dropna(subset=['income', 'predicted_income'])  # Remove rows with NaN in either column\n",
    "mse = mean_squared_error(customer_data_cleaned['income'], customer_data_cleaned['predicted_income'])\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c6750-495e-46db-b9eb-df509ea88e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... (your previous code)\n",
    "\n",
    "customer_data_cleaned = customer_data.dropna(subset=['income', 'predicted_income'])  # Remove rows with NaN\n",
    "\n",
    "if not customer_data_cleaned.empty: # Check if the dataframe is empty after dropping NaN values\n",
    "    mse = mean_squared_error(customer_data_cleaned['income'], customer_data_cleaned['predicted_income'])\n",
    "    print(f\"Mean Squared Error: {mse:.2f}.  My model is clearly… unique. (And by unique, I mean hilariously inaccurate.)\")\n",
    "else:\n",
    "    print(\"No non-NaN values to compute MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad9369-f300-4bfb-824e-788894665d2e",
   "metadata": {},
   "source": [
    "## Conclusion: My Data Science Internship: A Comedy of Errors (and a Really Big Number)\n",
    "\n",
    "So, what's the takeaway from all this? Did I revolutionize the field of customer prediction?  Absolutely not.  My model predicted that a goldfish would buy a timeshare in the Bahamas.  I'm pretty sure that violates several laws of nature, not to mention basic common sense.  The Mean Squared Error?  Let's just say it's a number that could probably be used to measure the distance between galaxies… in parsecs cubed.  Clearly, my algorithm is a masterpiece of… well, I'm still not entirely sure what.  Perhaps a masterpiece of statistical silliness?\n",
    "\n",
    "Did I learn valuable data science skills?  Debatable. I came into this internship thinking I was the next data science prodigy.  I left realizing that I'm probably better suited for a career in… well, anything that doesn't involve statistical modeling.  Maybe I'll become a professional dog walker.  At least dogs are predictable. (Unlike my data. And my model. And my career prospects.)\n",
    "\n",
    "But I did learn one thing: Sometimes, the best you can do is laugh at the chaos.  And maybe order another pizza.  And definitely update my resume.  \"Experienced in data cleaning (very experienced)\" sounds a lot better than \"Created a model that predicted the impossible.\"  Right?  Right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4049bda-0512-43c6-b1f5-bc406a586c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
